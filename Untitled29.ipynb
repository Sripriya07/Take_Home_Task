{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sripriya07/Take_Home_Task/blob/master/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLpYFwBsokN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avWmr5yYAnIb",
        "colab_type": "text"
      },
      "source": [
        "# Take Home Task :\n",
        "\n",
        "Importing all the necessary Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJB7L7GioiPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "% matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtftG9PDAtmx",
        "colab_type": "text"
      },
      "source": [
        "Loading the data :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs3IYn4DAl1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('TakeHome_task_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3j7AxgLA0Pl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d9d55ec-0ad1-4cd0-f85f-db9f4ef8d0c7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TvgdJXpBIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eba44213-551d-4daf-c9b0-43da29b5b4a5"
      },
      "source": [
        "df.keys()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['data', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmWFFdNRA6Ce",
        "colab_type": "text"
      },
      "source": [
        "Renaming column data to data_dict to remove ambiguity as one of the keys of dictionary entry in data column also named a s data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzEGDrp-pBK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns=['data_dict','label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iuh7YbopBO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcaef361-01c7-4369-ff0f-583e95a21acf"
      },
      "source": [
        "df['data_dict'].shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiApIPHVo9gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "23888ee0-27b2-4a2a-c25a-c474c35d95ac"
      },
      "source": [
        "df['data_dict'].describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                                                  2000\n",
              "unique                                                 2000\n",
              "top       {'id': 'DD7QWE', 'data': 'hi', 'message_order'...\n",
              "freq                                                      1\n",
              "Name: data_dict, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nwwe8UQBWd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c513ad3-1eca-4515-cabd-00e687dca3ba"
      },
      "source": [
        "df['data_dict'].dtype #to know the datatype of column"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giI_jkVowb-a",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQaxNZnHBbEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cef9ba4-94d5-40cc-9caf-130a1f88ea41"
      },
      "source": [
        "df['data_dict'][0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"{'id': 'KG0OUA', 'data': 'Good morning', 'message_order': 2, 'comments': ['']}\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0v71rs6BksN",
        "colab_type": "text"
      },
      "source": [
        "As we can see ,the entries of each row are strings which contains a dictionary.So,removing the '' '' punctuation from all the rows of the column data_dict to make it into a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaDNwuCmBe7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ast\n",
        "for i in range(2000):\n",
        "     df.data_dict[i]=ast.literal_eval(df.data_dict[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIwJVbtjB8q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36d08b4a-8a66-4201-8b16-0487af052005"
      },
      "source": [
        "df.data_dict[1999]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comments': [''], 'data': 'No bike', 'id': 'UGBYIK', 'message_order': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNpof-VECKVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdad0740-689c-4b55-c45c-f137e3aafcde"
      },
      "source": [
        "df.data_dict[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comments': [''], 'data': 'Good morning', 'id': 'KG0OUA', 'message_order': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yChE9o98CXlr",
        "colab_type": "text"
      },
      "source": [
        "Now,all the row entries are converted into dictionary in the column data_dict.Create a new Dataframe and load all the dictionary key value pairs by splitting them into columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqPvUUcYCNPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bacada50-3fe0-4d17-c82d-010172d785e4"
      },
      "source": [
        "df_1=pd.DataFrame()\n",
        "for i in range(2000):\n",
        "    df_1=df_1.append(pd.DataFrame(df.data_dict[i]))\n",
        "    \n",
        "    \n",
        "df_1.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRAPRCeVComm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "e3f4af52-242a-4cd7-e1ba-eaace31c5ef5"
      },
      "source": [
        "df_1.tail()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>message_order</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2RG46Y</td>\n",
              "      <td>OK by</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HCTZ3F</td>\n",
              "      <td>LL</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ITXTOW</td>\n",
              "      <td>Ok sir</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IOKVYD</td>\n",
              "      <td>Hello</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UGBYIK</td>\n",
              "      <td>No bike</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id     data  message_order comments\n",
              "0  2RG46Y    OK by              4         \n",
              "0  HCTZ3F       LL              5         \n",
              "0  ITXTOW   Ok sir              2         \n",
              "0  IOKVYD    Hello              4         \n",
              "0  UGBYIK  No bike              0         "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdS-OCOcCs09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4ad5258f-279e-4be1-ec64-dccf2ec68eec"
      },
      "source": [
        "df=pd.DataFrame(df)\n",
        "df.tail()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_dict</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>{'id': '2RG46Y', 'data': 'OK by', 'message_ord...</td>\n",
              "      <td>dontMeetRequirements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>{'id': 'HCTZ3F', 'data': 'LL', 'message_order'...</td>\n",
              "      <td>notInterested</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>{'id': 'ITXTOW', 'data': 'Ok sir', 'message_or...</td>\n",
              "      <td>whoAreYou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>{'id': 'IOKVYD', 'data': 'Hello', 'message_ord...</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>{'id': 'UGBYIK', 'data': 'No bike', 'message_o...</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              data_dict                 label\n",
              "1995  {'id': '2RG46Y', 'data': 'OK by', 'message_ord...  dontMeetRequirements\n",
              "1996  {'id': 'HCTZ3F', 'data': 'LL', 'message_order'...         notInterested\n",
              "1997  {'id': 'ITXTOW', 'data': 'Ok sir', 'message_or...             whoAreYou\n",
              "1998  {'id': 'IOKVYD', 'data': 'Hello', 'message_ord...              greeting\n",
              "1999  {'id': 'UGBYIK', 'data': 'No bike', 'message_o...              greeting"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utzXmnlzC1Gc",
        "colab_type": "text"
      },
      "source": [
        "Now,Concatenating two Dataframes into a single Dataframe by using the concat()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C6fhKF2Cy1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "a84c46d5-e22b-4f7b-a0e6-dd58883d5244"
      },
      "source": [
        "df.reset_index(drop=True,inplace=True)\n",
        "df_1.reset_index(drop=True,inplace=True)\n",
        "df_3=pd.concat([df,df_1],axis=1)\n",
        "df_3.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_dict</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>message_order</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'id': 'KG0OUA', 'data': 'Good morning', 'mess...</td>\n",
              "      <td>location</td>\n",
              "      <td>KG0OUA</td>\n",
              "      <td>Good morning</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'id': 'L9DC9H', 'data': 'Location', 'message_...</td>\n",
              "      <td>whoAreYou</td>\n",
              "      <td>L9DC9H</td>\n",
              "      <td>Location</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'id': 'ZQR6R5', 'data': 'hi', 'message_order'...</td>\n",
              "      <td>whoAreYou</td>\n",
              "      <td>ZQR6R5</td>\n",
              "      <td>hi</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'id': 'RH0M4E', 'data': 'Hi', 'message_order'...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>RH0M4E</td>\n",
              "      <td>Hi</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'id': 'WLVX8I', 'data': 'Hello', 'message_ord...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>WLVX8I</td>\n",
              "      <td>Hello</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           data_dict  ... comments\n",
              "0  {'id': 'KG0OUA', 'data': 'Good morning', 'mess...  ...         \n",
              "1  {'id': 'L9DC9H', 'data': 'Location', 'message_...  ...         \n",
              "2  {'id': 'ZQR6R5', 'data': 'hi', 'message_order'...  ...         \n",
              "3  {'id': 'RH0M4E', 'data': 'Hi', 'message_order'...  ...         \n",
              "4  {'id': 'WLVX8I', 'data': 'Hello', 'message_ord...  ...         \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s55xf9ewE_sF",
        "colab_type": "text"
      },
      "source": [
        "Dropping unncessary columns like data_dict,as we have already split the items in it and also comments columns as it has no entries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q4FRuprEN3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3.drop(['data_dict','comments'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ2V2TaLFRGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "833a6658-71a9-40d4-c108-a37495efa487"
      },
      "source": [
        "df_3.shape # printing the shape "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZtpP7PjFXQQ",
        "colab_type": "text"
      },
      "source": [
        "Printing the first 5 entries if the resulted Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-WOuOdCFSqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "556cad9a-682a-4b9c-fbb0-85c88512d25b"
      },
      "source": [
        "df_3.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>message_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>location</td>\n",
              "      <td>KG0OUA</td>\n",
              "      <td>Good morning</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>whoAreYou</td>\n",
              "      <td>L9DC9H</td>\n",
              "      <td>Location</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>whoAreYou</td>\n",
              "      <td>ZQR6R5</td>\n",
              "      <td>hi</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>greeting</td>\n",
              "      <td>RH0M4E</td>\n",
              "      <td>Hi</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>greeting</td>\n",
              "      <td>WLVX8I</td>\n",
              "      <td>Hello</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label      id          data  message_order\n",
              "0   location  KG0OUA  Good morning              2\n",
              "1  whoAreYou  L9DC9H      Location              5\n",
              "2  whoAreYou  ZQR6R5            hi              5\n",
              "3   greeting  RH0M4E            Hi              4\n",
              "4   greeting  WLVX8I         Hello              1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlJY9VMVFlBW",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the Data :\n",
        "\n",
        "Removing all the punctuations and symbols present in data_dict column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvdjbFMAFdgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3['data']=df_3['data'].str.replace('[^\\w\\s]','')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mP6OfcCFwWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c541c8c-b5d7-4509-99d6-b52e4e6462e2"
      },
      "source": [
        "df_3['data'].value_counts()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ok                                                              245\n",
              "Hi                                                              241\n",
              "Hello                                                            74\n",
              "Hii                                                              73\n",
              "hi                                                               36\n",
              "K                                                                36\n",
              "Hiii                                                             32\n",
              "No                                                               28\n",
              "Okay                                                             23\n",
              "Kk                                                               21\n",
              "Good morning                                                     18\n",
              "Hai                                                              17\n",
              "Hlo                                                              13\n",
              "ok                                                               13\n",
              "Where                                                            11\n",
              "Hi sir                                                           11\n",
              "Thanks                                                           11\n",
              "Location                                                         10\n",
              "Sorry                                                            10\n",
              "OK                                                               10\n",
              "I have no bike                                                    9\n",
              "Sir                                                               9\n",
              "Hello sir                                                         8\n",
              "Okk                                                               8\n",
              "Gn                                                                8\n",
              "Kkk                                                               8\n",
              "Good night                                                        8\n",
              "Gm                                                                7\n",
              "Hiiii                                                             7\n",
              "Ok sir                                                            7\n",
              "                                                               ... \n",
              "which location                                                    1\n",
              "Hy u                                                              1\n",
              "Oka                                                               1\n",
              "Sirwhich area                                                     1\n",
              "Sir I am intrasted Bat I have not a baik License is avalebal      1\n",
              "I dont have a licensed                                            1\n",
              "Hiii sir                                                          1\n",
              "I have LR only                                                    1\n",
              "sir                                                               1\n",
              "No need thank you                                                 1\n",
              "What areas bro                                                    1\n",
              "Hindi nai aate                                                    1\n",
              "Give address                                                      1\n",
              "Srryy                                                             1\n",
              "GD morning                                                        1\n",
              "But doesnt have driving license                                   1\n",
              "I will no bike  dl                                                1\n",
              "Hii good morning                                                  1\n",
              "LLR license                                                       1\n",
              "After 10 days am getting my LL                                    1\n",
              "Ha okl                                                            1\n",
              "Hello how are you                                                 1\n",
              "sorry                                                             1\n",
              "We dont have a interest                                           1\n",
              "IAM not interested                                                1\n",
              "Licences Bhi nahi hai                                             1\n",
              "Applications fee nai bhr skte                                     1\n",
              "okay                                                              1\n",
              " Good morning happy Friday                                        1\n",
              "                                                                  1\n",
              "Name: data, Length: 847, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1jVKM68wio3",
        "colab_type": "text"
      },
      "source": [
        " # Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kRT9jcCF7oq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "47a8e8d3-79c0-42eb-ad7e-08a9ce0010de"
      },
      "source": [
        "plt.figure(8)\n",
        "plt.scatter(df_3['data'],df_3['label'])\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAD8CAYAAAA2T650AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ0KOVkDG4UP",
        "colab_type": "text"
      },
      "source": [
        "Now,Converting all the letters in the data columns into lowercase as it reduces the duplicates of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxLoy0e6NGGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "d410e9db-c163-40d6-e56c-f0b208b28bed"
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "df_3.groupby('label').data.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFzCAYAAADxBEqxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAPAwIQaAAb2/wFSYiFKd9RLFAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9xB1KmaGL2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3['data']=df_3['data'].apply(lambda x:\" \".join(x.lower() for x in x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3_tA6SGMcgr",
        "colab_type": "text"
      },
      "source": [
        "Rearranging the columns :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUhEZTiMUGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21d020ff-5d2b-44c7-dc8e-09008cfec2af"
      },
      "source": [
        "cols=df_3.columns.to_list()\n",
        "cols"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label', 'id', 'data', 'message_order']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IUS3_foMkKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols=cols[1:]+cols[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMYlRuJzMpie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4af84de-7417-4fcd-82c0-47c767382be7"
      },
      "source": [
        "cols"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'data', 'message_order', 'label']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hufkPvX4MqK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3=df_3[cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf5hdh8uMt8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "8e821663-e749-4fa4-e0f5-6410f77afe04"
      },
      "source": [
        "df_3.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>message_order</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KG0OUA</td>\n",
              "      <td>good morning</td>\n",
              "      <td>2</td>\n",
              "      <td>location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L9DC9H</td>\n",
              "      <td>location</td>\n",
              "      <td>5</td>\n",
              "      <td>whoAreYou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ZQR6R5</td>\n",
              "      <td>hi</td>\n",
              "      <td>5</td>\n",
              "      <td>whoAreYou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RH0M4E</td>\n",
              "      <td>hi</td>\n",
              "      <td>4</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WLVX8I</td>\n",
              "      <td>hello</td>\n",
              "      <td>1</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id          data  message_order      label\n",
              "0  KG0OUA  good morning              2   location\n",
              "1  L9DC9H      location              5  whoAreYou\n",
              "2  ZQR6R5            hi              5  whoAreYou\n",
              "3  RH0M4E            hi              4   greeting\n",
              "4  WLVX8I         hello              1   greeting"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzGwh0RoMvQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b0156f0-aa67-4e24-eea8-f4a7b3f799d4"
      },
      "source": [
        "df_3['label'].unique()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['location', 'whoAreYou', 'greeting', 'dontMeetRequirements',\n",
              "       'notInterested'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk6DRP9aNioP",
        "colab_type": "text"
      },
      "source": [
        "As,there are 5 unique labels in the label,mapping each of the label to a numeric value using map().Hence,this would become a 5 categorical classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrEt6OPcM31u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_mapping={'location':0,'whoAreYou':1,'greeting':2,'dontMeetRequirements':3,'notInterested':4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuMNUY2hM-d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_3['label']=df_3['label'].map(output_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Pd2g4jNSm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c91bdfa1-a5e4-41f2-e4f8-d4106cb90825"
      },
      "source": [
        "df_3.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>message_order</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KG0OUA</td>\n",
              "      <td>good morning</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L9DC9H</td>\n",
              "      <td>location</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ZQR6R5</td>\n",
              "      <td>hi</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RH0M4E</td>\n",
              "      <td>hi</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WLVX8I</td>\n",
              "      <td>hello</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id          data  message_order  label\n",
              "0  KG0OUA  good morning              2      0\n",
              "1  L9DC9H      location              5      1\n",
              "2  ZQR6R5            hi              5      1\n",
              "3  RH0M4E            hi              4      2\n",
              "4  WLVX8I         hello              1      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbDnoctJOGgq",
        "colab_type": "text"
      },
      "source": [
        "Now,our data is preprocessed and ready for training.Lets try with different algorithms and find out which one works well.So,initially importing necessary libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvlVf4X1wpXs",
        "colab_type": "text"
      },
      "source": [
        "# Model Training using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TS5W9AhOEHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5YJ3hUVOlAi",
        "colab_type": "text"
      },
      "source": [
        "pipeline of feature engineering and model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWMyAoPqOgip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Pipeline([('vectorizer', CountVectorizer()),\n",
        " ('tfidf', TfidfTransformer()),\n",
        " ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
        "#the class_weight=\"balanced\" option tries to remove the biasedness of model towards majority sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inoxgknlOvzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paramater selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vectorizer__ngram_range': [(1, 1), (1, 2),(2,2),(2,3),(3,3)],\n",
        "               'tfidf__use_idf': (True, False)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7JGaI7PPK-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs_clf_svm = GridSearchCV(model, parameters, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ok2B545PO7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b4da40-08a8-49b7-9968-0168c85d88c3"
      },
      "source": [
        "X = df_3['data']\n",
        "y = df_3['label']\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(X) # Fit the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=42)\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1540, 821) (460, 821)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0F7R4tKPSd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8be4f5db-be86-498d-e67e-130a13b9dd4e"
      },
      "source": [
        "X = df_3['data']\n",
        "y = df_3['label']\n",
        "\n",
        "gs_clf_svm = gs_clf_svm.fit(X,y)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning:\n",
            "\n",
            "The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38R5jmm8PYax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1734c6a8-d5b8-4772-db02-2ec02318b78c"
      },
      "source": [
        "print(gs_clf_svm.best_score_*100)\n",
        "print(gs_clf_svm.best_params_)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.099999999999998\n",
            "{'tfidf__use_idf': False, 'vectorizer__ngram_range': (3, 3)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8sF4UtERmhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_3['data'], df_3['label'],test_size=0.33)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF4XmayIPju9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07ed6c57-61f0-4639-f175-2a48ae45e1e1"
      },
      "source": [
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "\n",
        "print(train_y.shape,valid_y.shape)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1340,) (660,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl8Ld1tQkEjt",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering :\n",
        "The next step is the feature engineering step. In this step, raw text data will be transformed into feature vectors and new features will be created using the existing dataset. We will implement the following different ideas in order to obtain relevant features from our dataset.\n",
        "\n",
        "1)Count Vectors as features\n",
        "\n",
        "2) TF-IDF Vectors as features\n",
        "\n",
        "       -Word level\n",
        "       \n",
        "       -N-Gram level\n",
        "       \n",
        "       -Character level\n",
        "3) Word Embeddings as features\n",
        "\n",
        "4) Text / NLP based features\n",
        "\n",
        "5) Topic Models as features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-amrnpx2lnR6",
        "colab_type": "text"
      },
      "source": [
        "**Count Vectors as features:**\n",
        "\n",
        "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uCVoXTCQs3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "159dc977-ddd2-4474-9731-3c6fdc88f400"
      },
      "source": [
        "# create a count vectorizer object \n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(df_3['data'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)\n",
        "\n",
        "xtrain_count"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1340x839 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3074 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He6_w9edl5Ys",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF Vectors as features :**\n",
        "\n",
        "TF-IDF score represents the relative importance of a term in the document and the entire corpus. TF-IDF score is composed by two terms: the first computes the normalized Term Frequency (TF), the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
        "\n",
        "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
        "\n",
        "IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
        "\n",
        "TF-IDF Vectors can be generated at different levels of input tokens (words, characters, n-grams)\n",
        "\n",
        "a. **Word Level TF-IDF**  : Matrix representing tf-idf scores of every term in different documents\n",
        "\n",
        "b. **N-gram Level TF-IDF** : N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
        "\n",
        "c. **Character Level TF-IDF** : Matrix representing tf-idf scores of character level n-grams in the corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1rLwqV4maXK",
        "colab_type": "text"
      },
      "source": [
        "a) **word level tf-idf** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wpoRyyPRamg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df_3['data'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HdMTUWJmjU4",
        "colab_type": "text"
      },
      "source": [
        "b) **ngram level tf-idf** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyVGbMbTRyVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,50), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df_3['data'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVvGSqSWmzXt",
        "colab_type": "text"
      },
      "source": [
        "c) **characters level tf-idf** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ0Eix_CSNRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(1,50), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df_3['data'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ43Q_cSm6AW",
        "colab_type": "text"
      },
      "source": [
        "**Word Embeddings :**\n",
        "\n",
        "A word embedding is a form of representing words and documents using a dense vector representation. The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used. Word embeddings can be trained using the input corpus itself or can be generated using pre-trained word embeddings such as Glove, FastText, and Word2Vec. Any one of them can be downloaded and used as transfer learning.\n",
        "\n",
        "File can be downloaded as follows :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UMIMTaYSV8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "3da75b94-3f51-4bd3-b0fd-eb9d77509f9e"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-30 05:10:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: wiki-news-300d-1M.vec.zip\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  41.8MB/s    in 17s     \n",
            "\n",
            "2019-07-30 05:11:02 (37.3 MB/s) - wiki-news-300d-1M.vec.zip saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJNYwuVCnVCw",
        "colab_type": "text"
      },
      "source": [
        "Now,Unzip the zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_kNi3WdSa4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "66f9743b-f232-4c3a-b6e9-0293b29b68ad"
      },
      "source": [
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgdIPqICnbZI",
        "colab_type": "text"
      },
      "source": [
        "**load the pre-trained word-embedding vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkRoQInkSjVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V53MOduTnjib",
        "colab_type": "text"
      },
      "source": [
        "create a tokenizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uKhFCMiStRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(df_3['data'])\n",
        "word_index = token.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYs-riPEn1xC",
        "colab_type": "text"
      },
      "source": [
        "Now,convert text to sequence of tokens and pad them to ensure equal length vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z36JFPeIS0iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zYsAmERn7e8",
        "colab_type": "text"
      },
      "source": [
        "create token-embedding mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulgV0Gj0S7pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Okq0AwooAha",
        "colab_type": "text"
      },
      "source": [
        "Now,Let's train a LDA Model.LDA is an iterative model which starts from a fixed number of topics. Each topic is represented as a distribution over words, and each document is then represented as a distribution over topics. Although the tokens themselves are meaningless, the probability distributions over words provided by the topics provide a sense of the different ideas contained in the documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geqDKXOdTNQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
        "X_topics = lda_model.fit_transform(xtrain_count)\n",
        "topic_word = lda_model.components_ \n",
        "vocab = count_vect.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NbA-gskTRr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view the topic models\n",
        "n_top_words = 10\n",
        "topic_summaries = []\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "    topic_summaries.append(' '.join(topic_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxS4ukQxokDU",
        "colab_type": "text"
      },
      "source": [
        "# Model Building\n",
        "The final step in the text classification framework is to train a classifier using the features created in the previous step. There are many different choices of machine learning models which can be used to train a final model. I have  implemented the  following different classifiers :\n",
        "\n",
        "Naive Bayes Classifier\n",
        "\n",
        "Linear Classifier\n",
        "\n",
        "Support Vector Machine\n",
        "\n",
        "Bagging Models\n",
        "\n",
        "Boosting Models\n",
        "\n",
        "Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRVAE7m9TU1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mo-oBgro3-G",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOXvS-Rxo-fH",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes on Count Vectors :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrD-e5NITXzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28325820-5927-4f7f-acc9-e28fd4b7228f"
      },
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print (\"NB, Count Vectors: \", accuracy)\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB, Count Vectors:  0.31666666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AofKRgFlpHRF",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes on Word Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw-n77XUThYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "090fc527-f677-436e-be5a-d4322d3b06cd"
      },
      "source": [
        "\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"NB, WordLevel TF-IDF: \", accuracy)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB, WordLevel TF-IDF:  0.3242424242424242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy_-gbTLpPm7",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes on Ngram Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuC6kPkBcPA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9e8670c-1469-4559-8c23-3a0efe0dae0e"
      },
      "source": [
        "\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print( \"NB, N-Gram Vectors: \", accuracy)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB, N-Gram Vectors:  0.3242424242424242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RrCLIk6pXp-",
        "colab_type": "text"
      },
      "source": [
        "**Naive Bayes on Character Level TF IDF Vectors**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsyOoB-6cTY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4fe800-473c-4b61-ac61-a748ff3d125a"
      },
      "source": [
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print( \"NB, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB, CharLevel Vectors:  0.32575757575757575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6twvc9e7pd99",
        "colab_type": "text"
      },
      "source": [
        "# Linear Classifier\n",
        "\n",
        "\n",
        "**Linear Classifier on Count Vectors :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiFhmCdCcaJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "4abfec54-4b9a-4dbc-ad4f-85240aeb1e9a"
      },
      "source": [
        "\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
        "print( \"LR, Count Vectors: \", accuracy)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR, Count Vectors:  0.3181818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
            "\n",
            "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning:\n",
            "\n",
            "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6qfzRx5pm6P",
        "colab_type": "text"
      },
      "source": [
        "**Linear Classifier on Word Level TF IDF Vectors :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UecTEGp4cdy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "b3ac234e-815f-453e-f29a-cc2257364678"
      },
      "source": [
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"LR, WordLevel TF-IDF: \", accuracy*100)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR, WordLevel TF-IDF:  32.57575757575758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
            "\n",
            "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning:\n",
            "\n",
            "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2gm5DwSqSBv",
        "colab_type": "text"
      },
      "source": [
        "**Linear Classifier on Ngram Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ_8jc1iclo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7fd47f50-fa29-433f-822a-033a68dc3e10"
      },
      "source": [
        "\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print (\"LR, N-Gram Vectors: \", accuracy)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR, N-Gram Vectors:  0.3181818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
            "\n",
            "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning:\n",
            "\n",
            "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tPHVzADqXRs",
        "colab_type": "text"
      },
      "source": [
        "**Linear Classifier on Character Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgOZuyNTdS5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "c3578fc9-cc25-4715-d569-fef9d955a56a"
      },
      "source": [
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print (\"LR, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR, CharLevel Vectors:  0.3106060606060606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning:\n",
            "\n",
            "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning:\n",
            "\n",
            "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZgVbXXqd3C",
        "colab_type": "text"
      },
      "source": [
        "# SVM\n",
        "\n",
        "**SVM on Ngram Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcv4BB3CdYt2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "243f16de-fcf7-45ef-e831-a5ee69fa0c39"
      },
      "source": [
        "\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print (\"SVM, N-Gram Vectors: \", accuracy)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM, N-Gram Vectors:  0.31666666666666665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning:\n",
            "\n",
            "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4I1FQU1qmiw",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "**RF on Count Vectors** :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCNo0vEGddRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c6c47478-6cd5-4a9c-deb9-28fc180c4fde"
      },
      "source": [
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
        "print (\"RF, Count Vectors: \", accuracy)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF, Count Vectors:  0.296969696969697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n",
            "\n",
            "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaKC_R7NqwIP",
        "colab_type": "text"
      },
      "source": [
        "**RF on Word Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHj7esF-dgfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c36d1455-c8ce-4550-f936-a7745a9349f2"
      },
      "source": [
        "\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"RF, WordLevel TF-IDF: \", accuracy)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF, WordLevel TF-IDF:  0.28939393939393937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning:\n",
            "\n",
            "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj8BU2KYuHma",
        "colab_type": "text"
      },
      "source": [
        "# Extreme Gradient Boosting :\n",
        "\n",
        "**Extereme Gradient Boosting on Count Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_b7c9JsdkZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e435fbaf-8d55-4b47-d01d-4892defb1402"
      },
      "source": [
        "\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
        "print (\"Xgb, Count Vectors: \", accuracy)\n"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xgb, Count Vectors:  0.3151515151515151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtlXsmQruSlt",
        "colab_type": "text"
      },
      "source": [
        "**Extereme Gradient Boosting on Word Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-x_1CS9dpkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e04fac0-07c3-4848-cc15-2ade56704b52"
      },
      "source": [
        "\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
        "print (\"Xgb, WordLevel TF-IDF: \", accuracy)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xgb, WordLevel TF-IDF:  0.31666666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUHtWe-uYSm",
        "colab_type": "text"
      },
      "source": [
        "**Extereme Gradient Boosting on Character Level TF IDF Vectors** :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCkdj_Ddufo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fa7da50-2357-4143-c6df-6f7647c11346"
      },
      "source": [
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
        "print (\"Xgb, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xgb, CharLevel Vectors:  0.31212121212121213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az1c8Gzad5v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REkBWsLah9w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upukkUxXu8Xd",
        "colab_type": "text"
      },
      "source": [
        "# Bi-Directional LSTM Neural Network :\n",
        "\n",
        "Initially, Import all the necessary libraries to build this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq_HB0J_h-BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkGxmOiaiGSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8_NGqZiHRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "178a5388-5b7b-4382-c31d-927474ed1cf0"
      },
      "source": [
        "# reading data\n",
        "df = pd.read_csv('output_file.csv') # output_file.csv is the file which we saved after text preprocessing\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)\n",
        "print('Shape of dataset ',df.shape)\n",
        "print(df.columns)\n",
        "print('No. of unique classes',len(set(df['label'])))"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of dataset  (1999, 5)\n",
            "Index(['Unnamed: 0', 'id', 'data', 'message_order', 'label'], dtype='object')\n",
            "No. of unique classes 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhccZQDgiMpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "macronum=sorted(set(df['label']))\n",
        "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
        "\n",
        "def fun(i):\n",
        "    return macro_to_id[i]\n",
        "\n",
        "df['label']=df['label'].apply(fun)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XtV-O3viQ3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts1 = []\n",
        "labels1 = []\n",
        "\n",
        "\n",
        "for idx in range(0,df.data.shape[0]):\n",
        "    text1 = BeautifulSoup(df.data[idx])\n",
        "    texts1.append(str(text1.get_text().encode()))\n",
        "\n",
        "for idx in df['label']:\n",
        "    labels1.append(idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AijkbT9siU_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "720a4f37-916a-43c7-e494-2d26a6f5323b"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts1)\n",
        "sequences = tokenizer.texts_to_sequences(texts1)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Number of Unique Tokens',len(word_index))"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Tokens 1143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsWOb_V8vUTD",
        "colab_type": "text"
      },
      "source": [
        "Using pretrained word embedding model.It can be downloaded as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebUYbGIriY1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c262ebd7-8ded-4b6b-d841-794a84d64768"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-30 06:20:49--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-07-30 06:20:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-07-30 06:20:49--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: glove.6B.zip\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  97.6MB/s    in 8.6s    \n",
            "\n",
            "2019-07-30 06:20:58 (95.7 MB/s) - glove.6B.zip saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDnpUECidZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "96fb1e06-d55d-4cea-9e2e-ffdfbf54b630"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIwXKwkrvrgS",
        "colab_type": "text"
      },
      "source": [
        "Padding and splitting the data into x_train,y_train and x_test,y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTD_Os1uii3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "349ad4be-a7b5-4fc6-8f50-42cf73a1af48"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "\n",
        "labels1 = to_categorical(np.asarray(labels1))\n",
        "print('Shape of Data Tensor:', data.shape)\n",
        "print('Shape of Label Tensor:', labels1.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels1 = labels1[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-nb_validation_samples]\n",
        "y_train = labels1[:-nb_validation_samples]\n",
        "x_val = data[-nb_validation_samples:]\n",
        "y_val = labels1[-nb_validation_samples:]"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Data Tensor: (1999, 1000)\n",
            "Shape of Label Tensor: (1999, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDy5L0dLinkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8349374-f81a-4042-f822-a251fad273dd"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors in Glove 6B 100d.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqG931EhirgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Hy9FLEiv0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGMaBOe0iz6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "084e06f5-2cc9-4a49-fb2e-9cceb9def459"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
        "preds = Dense(len(macronum), activation='softmax')(l_lstm)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"Bidirectional LSTM\")\n",
        "model.summary()"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bidirectional LSTM\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         114400    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 5)                 1005      \n",
            "=================================================================\n",
            "Total params: 276,205\n",
            "Trainable params: 276,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiGTyXlhi3QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp=ModelCheckpoint('model_rnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1I96Ulgi74W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "640ea41b-d449-4eb9-d07c-0c17c9c2adc9"
      },
      "source": [
        "history=model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=15, batch_size=2,callbacks=[cp])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0730 06:23:09.322814 139991816406912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1600 samples, validate on 399 samples\n",
            "Epoch 1/15\n",
            "1600/1600 [==============================] - 926s 579ms/step - loss: 1.5070 - acc: 0.2881 - val_loss: 1.5005 - val_acc: 0.2281\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.22807, saving model to model_rnn.hdf5\n",
            "Epoch 2/15\n",
            "1600/1600 [==============================] - 918s 574ms/step - loss: 1.4858 - acc: 0.3156 - val_loss: 1.5253 - val_acc: 0.2030\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.22807\n",
            "Epoch 3/15\n",
            "1600/1600 [==============================] - 916s 572ms/step - loss: 1.4810 - acc: 0.3094 - val_loss: 1.4522 - val_acc: 0.3784\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.22807 to 0.37845, saving model to model_rnn.hdf5\n",
            "Epoch 4/15\n",
            "1600/1600 [==============================] - 920s 575ms/step - loss: 1.4687 - acc: 0.3225 - val_loss: 1.4367 - val_acc: 0.3709\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.37845\n",
            "Epoch 5/15\n",
            " 154/1600 [=>............................] - ETA: 13:31 - loss: 1.4492 - acc: 0.3636"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgHl1YU1i_tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}